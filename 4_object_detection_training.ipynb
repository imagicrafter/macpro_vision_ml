{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047f365a-2dd5-4c2c-b4f7-51a00c1d563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup and Installation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üè† Roof Damage Object Detection Training\")\n",
    "print(\"üîß MacBook Pro M4 Optimized\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install required packages\n",
    "print(\"üì¶ Installing YOLOv8...\")\n",
    "# Uncomment the line below on first run\n",
    "# !pip install ultralytics\n",
    "\n",
    "# Check if installation was successful\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import torch\n",
    "    print(\"‚úÖ YOLOv8 installed successfully\")\n",
    "    print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"‚úÖ MPS available: {torch.backends.mps.is_available()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Installation failed: {e}\")\n",
    "    print(\"üí° Run: pip install ultralytics\")\n",
    "\n",
    "# Additional imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dc74c-3cc1-4ff5-b4db-23b89bba5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Dataset Verification\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîç Verifying Dataset Structure...\")\n",
    "\n",
    "# Check if dataset exists\n",
    "dataset_path = \"roof_damage_final\"  # Change this to your dataset name\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"‚ùå Dataset not found at: {dataset_path}\")\n",
    "    print(\"üí° Make sure you've run the data pipeline notebook first\")\n",
    "    print(\"üí° Available datasets:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if os.path.isdir(item) and any(sub in item.lower() for sub in ['roof', 'detection', 'dataset']):\n",
    "            print(f\"   - {item}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset found: {dataset_path}\")\n",
    "\n",
    "# Verify dataset structure\n",
    "required_dirs = [\n",
    "    f\"{dataset_path}/images/train\",\n",
    "    f\"{dataset_path}/images/val\", \n",
    "    f\"{dataset_path}/labels/train\",\n",
    "    f\"{dataset_path}/labels/val\",\n",
    "    f\"{dataset_path}/data.yaml\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìÅ Checking dataset structure:\")\n",
    "for dir_path in required_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        if dir_path.endswith('.yaml'):\n",
    "            print(f\"‚úÖ {dir_path}\")\n",
    "        else:\n",
    "            count = len([f for f in os.listdir(dir_path) if not f.startswith('.')])\n",
    "            print(f\"‚úÖ {dir_path} ({count} files)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Missing: {dir_path}\")\n",
    "\n",
    "# Load and display dataset info\n",
    "if os.path.exists(f\"{dataset_path}/dataset_info.json\"):\n",
    "    with open(f\"{dataset_path}/dataset_info.json\", 'r') as f:\n",
    "        dataset_info = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Classes: {dataset_info['classes']}\")\n",
    "    print(f\"   Training images: {dataset_info['statistics']['train_images']}\")\n",
    "    print(f\"   Validation images: {dataset_info['statistics']['val_images']}\")\n",
    "    print(f\"   Total bounding boxes: {dataset_info['statistics']['total_boxes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6422c05-032f-4149-ab16-6936b0d8aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Evaluate results\n",
    "model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32433d33-f436-4b48-a2ad-6fde006fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Test inference\n",
    "results = model.predict('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b89d4b3-36fd-4b7d-9d7e-c014b0c01ba8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Complete YOLOv8 Object Detection Training for Roof Damage Detection\n",
    "# MacBook Pro M4 Optimized\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: Setup and Installation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üè† Roof Damage Object Detection Training\")\n",
    "print(\"üîß MacBook Pro M4 Optimized\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install required packages\n",
    "print(\"üì¶ Installing YOLOv8...\")\n",
    "# Uncomment the line below on first run\n",
    "!pip install ultralytics\n",
    "\n",
    "# Check if installation was successful\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import torch\n",
    "    print(\"‚úÖ YOLOv8 installed successfully\")\n",
    "    print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"‚úÖ MPS available: {torch.backends.mps.is_available()}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Installation failed: {e}\")\n",
    "    print(\"üí° Run: pip install ultralytics\")\n",
    "\n",
    "# Additional imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616bf7a-2b62-4c50-895c-2059d122a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: Dataset Verification\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîç Verifying Dataset Structure...\")\n",
    "\n",
    "# Check if dataset exists\n",
    "project_path = \"projects/roof_shingle_inspection\" # Change this to the project folder\n",
    "dataset_path = f\"{project_path}/pipeline\"  # Change this to your dataset name\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"‚ùå Dataset not found at: {dataset_path}\")\n",
    "    print(\"üí° Make sure you've run the data pipeline notebook first\")\n",
    "    print(\"üí° Available datasets:\")\n",
    "    for item in os.listdir('.'):\n",
    "        if os.path.isdir(item) and any(sub in item.lower() for sub in ['roof', 'detection', 'dataset']):\n",
    "            print(f\"   - {item}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Dataset found: {dataset_path}\")\n",
    "\n",
    "# Verify dataset structure\n",
    "required_dirs = [\n",
    "    f\"{dataset_path}/images/train\",\n",
    "    f\"{dataset_path}/images/val\", \n",
    "    f\"{dataset_path}/labels/train\",\n",
    "    f\"{dataset_path}/labels/val\",\n",
    "    f\"{dataset_path}/data.yaml\"\n",
    "]\n",
    "\n",
    "print(\"\\nüìÅ Checking dataset structure:\")\n",
    "for dir_path in required_dirs:\n",
    "    if os.path.exists(dir_path):\n",
    "        if dir_path.endswith('.yaml'):\n",
    "            print(f\"‚úÖ {dir_path}\")\n",
    "        else:\n",
    "            count = len([f for f in os.listdir(dir_path) if not f.startswith('.')])\n",
    "            print(f\"‚úÖ {dir_path} ({count} files)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Missing: {dir_path}\")\n",
    "\n",
    "# Load and display dataset info\n",
    "if os.path.exists(f\"{dataset_path}/dataset_info.json\"):\n",
    "    with open(f\"{dataset_path}/dataset_info.json\", 'r') as f:\n",
    "        dataset_info = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Classes: {dataset_info['classes']}\")\n",
    "    print(f\"   Training images: {dataset_info['statistics']['train_images']}\")\n",
    "    print(f\"   Validation images: {dataset_info['statistics']['val_images']}\")\n",
    "    print(f\"   Total bounding boxes: {dataset_info['statistics']['total_boxes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdba4d-0f61-4b77-bae8-1803cf0ebc04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 3: Model Configuration and Training Setup\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüéØ Setting up YOLOv8 Training...\")\n",
    "\n",
    "# Training configuration optimized for M4 Pro and small dataset\n",
    "training_config = {\n",
    "    'model_size': 'yolov8n',         # Nano version - fastest for small datasets\n",
    "    'epochs': 10,                       # More epochs for small dataset\n",
    "    'batch_size': 8,                    # Conservative for M4 Pro\n",
    "    'image_size': 640,                  # Standard YOLO input size\n",
    "    'device': 'mps',                    # Apple Silicon GPU\n",
    "    'learning_rate': 0.01,              # Default learning rate\n",
    "    'patience': 20,                     # Early stopping patience\n",
    "    'save_period': 10,                  # Save checkpoint every 10 epochs\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è  Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Create training directory\n",
    "training_dir = f\"{project_path}/training\"\n",
    "experiment_name = f\"v1\"\n",
    "os.makedirs(training_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÇ Training output: {training_dir}/{experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ff912-dc15-49e3-b190-55e39703c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Data Augmentation Preview (Optional)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüñºÔ∏è  Previewing Data Augmentation...\")\n",
    "\n",
    "def preview_augmentation(dataset_path, num_samples=3):\n",
    "    \"\"\"Show original images and potential augmentations\"\"\"\n",
    "    \n",
    "    train_images_dir = f\"{dataset_path}/images/train\"\n",
    "    image_files = [f for f in os.listdir(train_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"‚ùå No images found in training directory\")\n",
    "        return\n",
    "    \n",
    "    # Show a few sample images\n",
    "    fig, axes = plt.subplots(1, min(num_samples, len(image_files)), figsize=(15, 5))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, image_file in enumerate(image_files[:num_samples]):\n",
    "        image_path = os.path.join(train_images_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[i].imshow(image)\n",
    "        axes[i].set_title(f\"Training Image {i+1}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üì∏ Showing {min(num_samples, len(image_files))} sample training images\")\n",
    "    print(\"üí° YOLO will automatically apply augmentations during training:\")\n",
    "    print(\"   - Random rotations, flips, and crops\")\n",
    "    print(\"   - Color jittering and contrast changes\") \n",
    "    print(\"   - Mosaic and mixup augmentations\")\n",
    "\n",
    "# Run preview\n",
    "if os.path.exists(f\"{dataset_path}/images/train\"):\n",
    "    preview_augmentation(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2feaca-2a74-49b8-9a9e-bb25ed565db2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 5: Training Execution\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüöÄ Starting YOLOv8 Training...\")\n",
    "print(\"‚è±Ô∏è  Expected training time on M4 Pro: 15-25 minutes\")\n",
    "print(\"üíæ Progress will be saved automatically\")\n",
    "\n",
    "# Initialize model\n",
    "print(f\"üîÑ Loading pre-trained model: {training_config['model_size']}\")\n",
    "model = YOLO(training_config['model_size'])\n",
    "\n",
    "# Check data.yaml path\n",
    "data_yaml_path = f\"{dataset_path}/data.yaml\"\n",
    "if not os.path.exists(data_yaml_path):\n",
    "    print(f\"‚ùå data.yaml not found at: {data_yaml_path}\")\n",
    "    print(\"üí° Make sure you've run the data pipeline conversion\")\n",
    "else:\n",
    "    print(f\"‚úÖ Using dataset config: {data_yaml_path}\")\n",
    "\n",
    "# Start training\n",
    "print(\"\\nüèãÔ∏è  Training started...\")\n",
    "print(\"üìä Monitor progress below:\")\n",
    "\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=training_config['epochs'],\n",
    "        imgsz=training_config['image_size'],\n",
    "        batch=training_config['batch_size'],\n",
    "        device=training_config['device'],\n",
    "        project=training_dir,\n",
    "        name=experiment_name,\n",
    "        save_period=training_config['save_period'],\n",
    "        patience=training_config['patience'],\n",
    "        verbose=True,\n",
    "        # Augmentation settings for small dataset\n",
    "        hsv_h=0.015,        # Hue augmentation\n",
    "        hsv_s=0.7,          # Saturation augmentation  \n",
    "        hsv_v=0.4,          # Value augmentation\n",
    "        degrees=10,         # Rotation degrees\n",
    "        translate=0.1,      # Translation\n",
    "        scale=0.9,          # Scale\n",
    "        shear=0.0,          # Shear\n",
    "        perspective=0.0,    # Perspective\n",
    "        flipud=0.0,         # Flip up-down\n",
    "        fliplr=0.5,         # Flip left-right\n",
    "        mosaic=1.0,         # Mosaic augmentation\n",
    "        mixup=0.1,          # Mixup augmentation\n",
    "        copy_paste=0.1      # Copy-paste augmentation\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéâ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    print(\"üí° Try reducing batch size or checking dataset format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9412f4-f80a-44e6-a937-d43ea5c8b962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 6: Training Results Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìà Analyzing Training Results...\")\n",
    "\n",
    "# Path to training results\n",
    "results_path = f\"{training_dir}/{experiment_name}\"\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    # Display training curves\n",
    "    print(\"üìä Training Curves:\")\n",
    "    \n",
    "    # Check for results images\n",
    "    results_images = [\n",
    "        'results.png',          # Overall results\n",
    "        'confusion_matrix.png', # Confusion matrix  \n",
    "        'val_batch0_pred.png',  # Validation predictions\n",
    "        'train_batch0.png'      # Training batch sample\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_name in enumerate(results_images):\n",
    "        img_path = os.path.join(results_path, img_name)\n",
    "        if os.path.exists(img_path):\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(img_name.replace('.png', '').replace('_', ' ').title())\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'{img_name}\\nNot Found', \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show best model metrics\n",
    "    weights_path = os.path.join(results_path, 'weights', 'best.pt')\n",
    "    if os.path.exists(weights_path):\n",
    "        print(f\"‚úÖ Best model saved: {weights_path}\")\n",
    "        \n",
    "        # Load best model for evaluation\n",
    "        best_model = YOLO(weights_path)\n",
    "        \n",
    "        # Validate on test set\n",
    "        print(\"\\nüß™ Validating best model...\")\n",
    "        val_results = best_model.val()\n",
    "        \n",
    "        print(\"üìä Validation Metrics:\")\n",
    "        print(f\"   mAP50: {val_results.box.map50:.3f}\")\n",
    "        print(f\"   mAP50-95: {val_results.box.map:.3f}\")\n",
    "        print(f\"   Precision: {val_results.box.mp:.3f}\")\n",
    "        print(f\"   Recall: {val_results.box.mr:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Training results not found at: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f654651-e0a7-48dd-ac5f-a9a9701c91a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CELL 7: Inference Testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîÆ Testing Model Inference...\")\n",
    "\n",
    "# Load the best trained model\n",
    "weights_path = f\"{training_dir}/{experiment_name}/weights/best.pt\"\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    print(f\"üîÑ Loading trained model: {weights_path}\")\n",
    "    trained_model = YOLO(weights_path)\n",
    "    \n",
    "    # Test on validation images\n",
    "    val_images_dir = f\"{dataset_path}/images/val\"\n",
    "    if os.path.exists(val_images_dir):\n",
    "        val_images = [f for f in os.listdir(val_images_dir) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        print(f\"üß™ Testing on {len(val_images)} validation images...\")\n",
    "        \n",
    "        # Run inference on a few validation images\n",
    "        test_images = val_images[:3]  # Test first 3 images\n",
    "        \n",
    "        for i, img_name in enumerate(test_images):\n",
    "            img_path = os.path.join(val_images_dir, img_name)\n",
    "            \n",
    "            print(f\"\\nüñºÔ∏è  Testing: {img_name}\")\n",
    "            \n",
    "            # Run inference\n",
    "            results = trained_model.predict(\n",
    "                img_path,\n",
    "                save=True,\n",
    "                project=f\"{training_dir}/inference\", \n",
    "                name=f\"test_{i+1}\",\n",
    "                conf=0.25,  # Confidence threshold\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Display results\n",
    "            if len(results) > 0 and len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes\n",
    "                print(f\"   Detected {len(boxes)} objects:\")\n",
    "                \n",
    "                for j, box in enumerate(boxes):\n",
    "                    class_id = int(box.cls[0])\n",
    "                    confidence = float(box.conf[0])\n",
    "                    class_name = dataset_info['classes'][class_id] if 'dataset_info' in locals() else f\"class_{class_id}\"\n",
    "                    print(f\"     {j+1}. {class_name}: {confidence:.2f}\")\n",
    "            else:\n",
    "                print(\"   No objects detected\")\n",
    "        \n",
    "        print(f\"\\nüíæ Inference results saved to: {training_dir}/inference/\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Trained model not found: {weights_path}\")\n",
    "    print(\"üí° Make sure training completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a89d8-018d-4eb2-8f75-6b86497d9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Client Demo Setup\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüé¨ Setting up Client Demo...\")\n",
    "\n",
    "def create_demo_inference_function(model_path, class_names):\n",
    "    \"\"\"Create a simple function for client demonstrations\"\"\"\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        return None\n",
    "    \n",
    "    demo_model = YOLO(model_path)\n",
    "    \n",
    "    def detect_roof_damage(image_path, confidence_threshold=0.25):\n",
    "        \"\"\"\n",
    "        Detect roof damage in an image\n",
    "        \n",
    "        Args:\n",
    "            image_path (str): Path to image file\n",
    "            confidence_threshold (float): Minimum confidence for detections\n",
    "            \n",
    "        Returns:\n",
    "            dict: Detection results with bounding boxes and classifications\n",
    "        \"\"\"\n",
    "        \n",
    "        # Run inference\n",
    "        results = demo_model.predict(\n",
    "            image_path,\n",
    "            conf=confidence_threshold,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Parse results\n",
    "        detections = []\n",
    "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
    "            boxes = results[0].boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = float(box.conf[0])\n",
    "                bbox = box.xyxy[0].tolist()  # [x1, y1, x2, y2]\n",
    "                \n",
    "                detection = {\n",
    "                    'class': class_names[class_id],\n",
    "                    'confidence': confidence,\n",
    "                    'bbox': bbox,\n",
    "                    'severity': class_names[class_id]\n",
    "                }\n",
    "                detections.append(detection)\n",
    "        \n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'detections': detections,\n",
    "            'damage_found': len(detections) > 0,\n",
    "            'total_issues': len(detections)\n",
    "        }\n",
    "    \n",
    "    return detect_roof_damage\n",
    "\n",
    "# Create demo function\n",
    "if os.path.exists(weights_path) and 'dataset_info' in locals():\n",
    "    print(\"üîß Creating demo inference function...\")\n",
    "    \n",
    "    demo_function = create_demo_inference_function(\n",
    "        weights_path, \n",
    "        dataset_info['classes']\n",
    "    )\n",
    "    \n",
    "    if demo_function:\n",
    "        print(\"‚úÖ Demo function created successfully!\")\n",
    "        print(\"\\nüí° Usage example:\")\n",
    "        print(\"   result = demo_function('path/to/roof/image.jpg')\")\n",
    "        print(\"   print(f'Found {result[\\\"total_issues\\\"]} damage areas')\")\n",
    "        \n",
    "        # Test demo function on a validation image\n",
    "        if os.path.exists(val_images_dir) and len(val_images) > 0:\n",
    "            test_image = os.path.join(val_images_dir, val_images[0])\n",
    "            demo_result = demo_function(test_image)\n",
    "            \n",
    "            print(f\"\\nüß™ Demo test result:\")\n",
    "            print(f\"   Image: {os.path.basename(demo_result['image_path'])}\")\n",
    "            print(f\"   Damage found: {demo_result['damage_found']}\")\n",
    "            print(f\"   Total issues: {demo_result['total_issues']}\")\n",
    "            \n",
    "            for i, detection in enumerate(demo_result['detections']):\n",
    "                print(f\"   Detection {i+1}: {detection['class']} ({detection['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c097e57-e0f8-4324-bc29-7856602a20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: Export Model for Deployment\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüì¶ Exporting Model for Deployment...\")\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    export_model = YOLO(weights_path)\n",
    "    \n",
    "    # Export formats suitable for different deployment scenarios\n",
    "    export_formats = {\n",
    "        'onnx': 'Cross-platform deployment',\n",
    "        'coreml': 'iOS/macOS deployment', \n",
    "        'torchscript': 'PyTorch deployment'\n",
    "    }\n",
    "    \n",
    "    print(\"üîÑ Available export formats:\")\n",
    "    for fmt, description in export_formats.items():\n",
    "        print(f\"   {fmt}: {description}\")\n",
    "    \n",
    "    # Export to ONNX (most versatile)\n",
    "    try:\n",
    "        print(f\"\\nüì§ Exporting to ONNX format...\")\n",
    "        onnx_path = export_model.export(format='onnx')\n",
    "        print(f\"‚úÖ ONNX model exported: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  ONNX export failed: {e}\")\n",
    "    \n",
    "    # Export to CoreML for Apple ecosystem\n",
    "    try:\n",
    "        print(f\"\\nüì§ Exporting to CoreML format...\")\n",
    "        coreml_path = export_model.export(format='coreml')\n",
    "        print(f\"‚úÖ CoreML model exported: {coreml_path}\")\n",
    "        print(\"üí° This model can be used in iOS/macOS apps\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  CoreML export failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a83a4-7136-479c-8837-e3ddacc2097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Project Summary and Next Steps\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ ROOF DAMAGE DETECTION PROJECT COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Project summary\n",
    "summary = {\n",
    "    'Dataset': f\"{dataset_path} ({dataset_info['statistics']['total_boxes']} annotations)\" if 'dataset_info' in locals() else \"Unknown\",\n",
    "    'Model': 'YOLOv8 Nano',\n",
    "    'Training Time': '~20 minutes on M4 Pro',\n",
    "    'Status': 'Ready for client demo' if os.path.exists(weights_path) else 'Training incomplete'\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Project Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÅ Key Files:\")\n",
    "if os.path.exists(weights_path):\n",
    "    print(f\"   Trained Model: {weights_path}\")\n",
    "print(f\"   Training Results: {training_dir}/{experiment_name}/\")\n",
    "print(f\"   Dataset: {dataset_path}/\")\n",
    "\n",
    "print(f\"\\nüéØ Client Demo Ready:\")\n",
    "print(f\"   ‚úÖ Object detection model trained\")\n",
    "print(f\"   ‚úÖ Bounding box detection working\") \n",
    "print(f\"   ‚úÖ Multiple damage severity levels\")\n",
    "print(f\"   ‚úÖ Inference function created\")\n",
    "print(f\"   ‚úÖ Visualization tools available\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Test model on new roof images\")\n",
    "print(f\"   2. Collect feedback from client\")\n",
    "print(f\"   3. Gather more training data (100-500 images)\")\n",
    "print(f\"   4. Retrain for production deployment\")\n",
    "print(f\"   5. Deploy to client's preferred platform\")\n",
    "\n",
    "print(f\"\\nüí° For Production:\")\n",
    "print(f\"   ‚Ä¢ Collect 100-500 more annotated images\")\n",
    "print(f\"   ‚Ä¢ Train YOLOv8s or YOLOv8m for better accuracy\")\n",
    "print(f\"   ‚Ä¢ Implement automated damage assessment\")\n",
    "print(f\"   ‚Ä¢ Deploy via API or mobile app\")\n",
    "\n",
    "print(\"\\nüè† Ready to demonstrate professional roof damage detection!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2253eed-8a75-4808-b2c0-59f91d8c6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Image Demo\n",
    "client_photo = \"projects/roof_shingle_inspection/inference/roof_damage_demo.png\"\n",
    "result = demo_function(client_photo)\n",
    "\n",
    "if result['damage_found']:\n",
    "    print(f\"üö® DAMAGE DETECTED: {result['total_issues']} areas of concern\")\n",
    "    for detection in result['detections']:\n",
    "        severity = detection['class']\n",
    "        confidence = detection['confidence']\n",
    "        print(f\"  ‚Ä¢ {severity} (confidence: {confidence:.1%})\")\n",
    "else:\n",
    "    print(\"‚úÖ No damage detected in this roof section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717b9ea-4ff3-4918-bf36-1471ec38e39e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897631f-b273-433c-86b0-72fe7539bb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
